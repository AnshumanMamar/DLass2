{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8009603,"sourceType":"datasetVersion","datasetId":4717719}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torch.nn as nn\nimport math\nfrom torchvision.transforms import RandomResizedCrop, RandomHorizontalFlip, Resize, CenterCrop, ToTensor, Normalize, Compose\nimport shutil\nfrom tqdm import tqdm\nimport torch.optim as optim\nimport sys \nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split\nimport matplotlib.pyplot as plt\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  loading the data","metadata":{}},{"cell_type":"code","source":"# loading the data\ndef loader(t1data, valdata, t2data, batch):\n    bs=batch\n    bol1=True\n    bol2=False\n    train = torch.utils.data.DataLoader(t1data, batch_size=bs,num_workers =4, shuffle=bol1)\n    valid = torch.utils.data.DataLoader(valdata, batch_size=bs, num_workers =4,shuffle=bol1)\n    test = torch.utils.data.DataLoader(t2data, batch_size=bs, num_workers =4,shuffle=bol2)\n    allLoaders = {\n        'train' : train,\n        'valid' : valid,\n        'test'  : test\n    }\n    return allLoaders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get model function is defined here\ndef model_get(modelName):\n    bol =modelName.lower() == 'resnet50'\n    model = None\n    import torchvision as tv \n    if bol:\n        model = tv.models.resnet50(pretrained=True)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# performinig the transformation to match model input dimensions\ndef transform():\n    string ='Normalize'\n    valResize = 256 #134 #36\n    sizeChange = 224 #128#32\n    valCenterCrop = sizeChange\n    \n    \n    t1_t = Compose([RandomResizedCrop(sizeChange),\n                       RandomHorizontalFlip(),\n                       ToTensor(),\n                       Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n    val_t = Compose([Resize(valResize),\n                       CenterCrop(valCenterCrop),\n                       ToTensor(),\n                       Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n    t2_t = Compose([Resize((sizeChange,sizeChange)), \n                      ToTensor(), \n                      Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])])\n    \n    transforms = {\n        'training':   t1_t,\n        'validation': val_t,\n        'test': t2_t\n    }\n    \n    return transforms\n\n#Loading dataset fn\ndef data_load():\n    transforms=transform()\n    t1set  = torchvision.datasets.ImageFolder('/kaggle/input/dlasssssss2/inaturalist_12K/train', transforms['training'])\n    train, val = random_split(t1set, [8000, 1999])\n    t2set   = torchvision.datasets.ImageFolder('/kaggle/input/dlasssssss2/inaturalist_12K/val', transforms['test'])\n    return train, val, t2set","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how to check if cuda is available\ncuda = torch.cuda.is_available()\nif cuda == True:\n    device = torch.device(\"cuda\")\nif cuda != True:\n    device = torch.device(\"cpu\")\n    \nprint(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_change_classifier(model):\n    model.fc = nn.Sequential(nn.Linear(model.fc.in_features,500),\n                         nn.ReLU(),\n                         nn.Dropout(),\n                         nn.Linear(500,10))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"\ndef train(totalEpoch, allLoaders, model, opt, criterion, cuda):\n    \n\n    for epoch in range(1, totalEpoch+1):\n        \n        train_loss ,valid_loss= 0.0,0.0\n        \n        optimizer=opt\n        model.train()\n        tnum_correct,tnum_examples=0,0\n        for data, target in tqdm(allLoaders['train']):\n            # move to GPU\n            bol=cuda\n            if bol:\n                data, target = data.cuda(), target.cuda()\n                \n            opt.zero_grad()\n            \n            output = model(data)\n            loss = criterion(output, target)\n            \n            \n            loss.backward()\n            opt.step()\n            train_loss += loss.item()\n            \n            _, predicted = torch.max(output.data, 1)\n            tnum_examples += target.size(0)\n            tnum_correct += (predicted == target).sum().item()\n            \n        train_acc = (tnum_correct / tnum_examples) * 100\n        train_loss = train_loss / len(allLoaders['train'])\n\n        \n  \n        # validating the Model \n\n        model.eval()\n        num_correct ,num_examples= 0,0\n        \n        \n        \n        for data, target in tqdm(allLoaders['valid']):\n            bol=cuda\n            if bol:\n                data, target = data.cuda(), target.cuda()\n            \n            output = model(data)\n            loss = criterion(output, target)\n            \n            \n            \n            valid_loss += loss.item()\n            \n            _, val_predicted = torch.max(output.data, 1)\n            num_examples += target.size(0)\n            num_correct += (val_predicted == target).sum().item()\n           \n\n        valid_acc = (num_correct / num_examples) * 100\n        valid_loss = valid_loss / len(allLoaders['valid'])\n        \n        \n        print('Epoch: {}\\tTraining Loss: {:.6f}\\tTrain Accuracy: {:.2f}\\tValidation Loss: {:.6f}\\tvalidation Accuracy: {:.2f}'.format(\n            epoch, \n            train_loss,\n            train_acc,\n            valid_loss,\n            valid_acc\n            ))\n        \n        \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Freeze Layers","metadata":{}},{"cell_type":"code","source":"def freeze(model, strategy, k):\n    bol=k == 0\n    if bol:\n        return\n    bol=strategy == \"first\"\n    if bol:\n        layerNumber = 0\n        for _, layer in model.named_children():\n            layerNumber = layerNumber + 1\n            bol = layerNumber <= k\n            if bol:\n                for _, param in layer.named_parameters():\n                    param.requires_grad = False\n    bol=strategy == \"middle\"\n    if bol:\n        layerNumber = 0\n        for _, layer in model.named_children():\n            layerNumber = layerNumber + 1\n            bol=(len(list(model.named_children())) // 3  ) <= layerNumber < ((len(list(model.named_children())) // 3) * 2) \n            if bol:\n                for _, param in layer.named_parameters():\n                    param.requires_grad = False\n    bol=strategy == \"last\"\n    if bol:\n        layerNumber = 0\n        for _, layer in model.named_children():\n            layerNumber = layerNumber + 1\n            bol=(len(list(model.named_children())) - k + 1) <= layerNumber <= (len(list(model.named_children())))\n            if bol:\n                for _, param in layer.named_parameters():\n                    param.requires_grad = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sp_train(l,strategy):\n    config = {\n        'model_name':'ResNet50',\n        'totalEpoch': 1,\n        'learning_rate_1': 1e-4,\n        'learning_rate_2': 1e-4,\n        'batchnorm_pretrain':'YES',\n        'opt': 'sgd'\n    }\n    \n    modelName = config['model_name']\n    model = model_get(modelName)\n   \n    \n    datasetTrain, datasetVal, datasetTest = data_load()\n    batch_size = 64\n    allLoaders = loader(datasetTrain, datasetVal, datasetTest, batch_size)\n    \n    freeze(model,strategy,l)\n    model = model.to(device)\n    string = 'opt'\n    if config[string]=='sgd':\n        opt = optim.SGD(model.parameters(), lr=config['learning_rate_1'], momentum = 0.9)\n    if config[string]=='adam':\n        opt = optim.Adam(model.parameters(), lr=config['learning_rate_1'], betas=(0.9, 0.999))\n    criterion = nn.CrossEntropyLoss()\n    \n    _ = train(totalEpoch=config['totalEpoch'],\n                      allLoaders = allLoaders,\n                      model = model,\n                      opt = opt,\n                      criterion = criterion,\n                      cuda = cuda\n                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# training all layers","metadata":{}},{"cell_type":"code","source":"sp_train(0,'all')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# freezing first l layers","metadata":{}},{"cell_type":"code","source":"sp_train(3,'first')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# freezing last l layers","metadata":{}},{"cell_type":"code","source":"sp_train(3,'last')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# freezing middle l layers","metadata":{}},{"cell_type":"code","source":"sp_train(3,'middle')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}